# Speech-to-Image Generation using OpenAI Models

## Overview

This project utilizes OpenAI's Whisper and DALL-E-2 models to convert spoken language into images. It uses Streamlit for the user interface and OpenAI API for model interactions.

## Installation

1. Install the required Python packages:

    ```bash
    pip install -r requirements.txt
    ```

2. Set up OpenAI API key:

    - Sign up for an OpenAI API key at [OpenAI](https://beta.openai.com/signup/).
    - Set your API key as an environment variable:

        ```bash
        export OPENAI_API_KEY="your-api-key"
        ```

## Usage

1. Run the Streamlit app:

    ```bash
    streamlit run app.py
    ```

2. Open the provided Streamlit link in your web browser.

3. Click the "Click here to speak" button to record audio.

4. The recorded audio is then transcribed using the Whisper model.

5. The transcribed text is used as a prompt for the DALL-E-2 model to generate an image.

6. The generated image is displayed on the Streamlit app.

## File Structure

- `app.py`: Streamlit app script.
- `requirements.txt`: List of required Python packages.
- `input.wav`: Temporary audio file for user input.
- `generated_image.jpg`: Output image generated by the DALL-E-2 model.

## Notes

- This project assumes Python 3.6 or later.
- Make sure to keep your OpenAI API key confidential.

## Github account 

- https://github.com/NDSUKESH

