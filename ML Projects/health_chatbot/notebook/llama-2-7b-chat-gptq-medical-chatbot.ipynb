{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install accelerate peft trl datasets bitsandbytes auto-gptq optimum -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-07T04:20:23.399168Z","iopub.execute_input":"2023-12-07T04:20:23.399525Z","iopub.status.idle":"2023-12-07T04:20:42.922662Z","shell.execute_reply.started":"2023-12-07T04:20:23.399495Z","shell.execute_reply":"2023-12-07T04:20:42.921476Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    device = torch.cuda.get_device_name()\n    print(f\"CUDA device: {device}\")\n    print(f\"CUDA version: {torch.version.cuda}\")\nelse:\n    print(\"CUDA is not available on this system.\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:20:42.925036Z","iopub.execute_input":"2023-12-07T04:20:42.925872Z","iopub.status.idle":"2023-12-07T04:20:45.744098Z","shell.execute_reply.started":"2023-12-07T04:20:42.925829Z","shell.execute_reply":"2023-12-07T04:20:45.743189Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"CUDA device: Tesla T4\nCUDA version: 11.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn as nn\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM,GPTQConfig, TrainingArguments\nfrom peft import LoraConfig,prepare_model_for_kbit_training, get_peft_model\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:20:45.745133Z","iopub.execute_input":"2023-12-07T04:20:45.745497Z","iopub.status.idle":"2023-12-07T04:20:59.094294Z","shell.execute_reply.started":"2023-12-07T04:20:45.745472Z","shell.execute_reply":"2023-12-07T04:20:59.093345Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"DR-DRR/Medical_Customer_care\",split='train')\ndataset['text'][0]","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:20:59.096307Z","iopub.execute_input":"2023-12-07T04:20:59.096598Z","iopub.status.idle":"2023-12-07T04:21:07.503755Z","shell.execute_reply.started":"2023-12-07T04:20:59.096571Z","shell.execute_reply":"2023-12-07T04:21:07.502888Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset text/DR-DRR--Medical_Customer_care to /root/.cache/huggingface/datasets/text/DR-DRR--Medical_Customer_care-e19aadc132a87f29/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48964093fdff4068b211f0c845abd276"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/33.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"810a57bcdb624d83b38c3903b324189d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/191M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0260e4ccb0e84ad4adf4b7cd843daa11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"745917438fb84bda99292c6b13438435"}},"metadata":{}},{"name":"stdout","text":"Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/DR-DRR--Medical_Customer_care-e19aadc132a87f29/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST] Explain the importance of staying hydrated and its benefits for overall health. [/INST] Staying hydrated is crucial for maintaining your overall health. It helps regulate your body temperature, keeps your joints functioning smoothly, aids in digestion, and flushes out toxins. When you're properly hydrated, you'll notice improvements in your skin's appearance and feel more energetic. So, remember to drink water regularly throughout the day to reap these health benefits and keep dehydration symptoms like a dry mouth and dizziness at bay.</s>\""},"metadata":{}}]},{"cell_type":"code","source":"model_ckpt = \"TheBloke/Llama-2-7b-Chat-GPTQ\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_ckpt\n)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:21:07.505079Z","iopub.execute_input":"2023-12-07T04:21:07.505765Z","iopub.status.idle":"2023-12-07T04:21:08.506741Z","shell.execute_reply.started":"2023-12-07T04:21:07.505727Z","shell.execute_reply":"2023-12-07T04:21:08.505712Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a183c75f204c07905a6767d4e233dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b1e70df7a1a44d59163a18fb9a637da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0774d96c5f549f2a0abe19914c88246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29210e2fdb504123b1598a2b796f6655"}},"metadata":{}}]},{"cell_type":"code","source":"quantization_config = GPTQConfig(bits=4,disable_exllama=True,tokenizer=tokenizer)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_ckpt,\n    revision='main',\n    quantization_config=quantization_config,\n    device_map='auto')\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:21:08.508150Z","iopub.execute_input":"2023-12-07T04:21:08.508857Z","iopub.status.idle":"2023-12-07T04:21:38.749042Z","shell.execute_reply.started":"2023-12-07T04:21:08.508821Z","shell.execute_reply":"2023-12-07T04:21:38.748235Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ae047e839b4307af25b700cda78c07"}},"metadata":{}},{"name":"stderr","text":"You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c08a6d579b482a8b5d53b2fc776045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487540446545440da67871701c92d7a2"}},"metadata":{}}]},{"cell_type":"code","source":"lora_config = LoraConfig(r=16,\n                        lora_alpha=32,\n                        lora_dropout=0.05,\n                        bias='none',\n                        task_type='CAUSAL_LM',\n                        target_modules=[\n                                    \"q_proj\",\n                                    \"k_proj\",\n                                    \"v_proj\",\n                                    \"o_proj\",\n                                    \"gate_proj\",\n                                    \"up_proj\",\n                                    \"down_proj\",\n                                        ]\n)\nmodel = get_peft_model(model,lora_config)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:21:38.750131Z","iopub.execute_input":"2023-12-07T04:21:38.750400Z","iopub.status.idle":"2023-12-07T04:21:39.758259Z","shell.execute_reply.started":"2023-12-07T04:21:38.750376Z","shell.execute_reply":"2023-12-07T04:21:39.757264Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(output_dir='.',\n                                 dataloader_drop_last=True,\n                                 save_strategy='epoch',\n                                 num_train_epochs=1,\n                                 logging_steps=100,\n                                 max_steps=2000,\n                                 per_device_train_batch_size=1,\n                                 learning_rate=3e-4,\n                                 lr_scheduler_type='cosine',\n                                 warmup_steps=100,\n                                 fp16=True,\n                                 #gradient_accumulation_steps=2,\n                                 weight_decay=0.05,\n                                 report_to=None,\n                                 run_name='finetuning-llama2-chat-7b')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:21:39.759652Z","iopub.execute_input":"2023-12-07T04:21:39.760125Z","iopub.status.idle":"2023-12-07T04:21:45.183530Z","shell.execute_reply.started":"2023-12-07T04:21:39.760089Z","shell.execute_reply":"2023-12-07T04:21:45.182298Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(model=model,\n                    args=training_args,\n                    train_dataset = dataset,\n                    dataset_text_field='text',\n                    max_seq_length=1024,\n                    tokenizer=tokenizer,\n                    packing=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:21:45.185388Z","iopub.execute_input":"2023-12-07T04:21:45.186407Z","iopub.status.idle":"2023-12-07T04:22:56.952395Z","shell.execute_reply.started":"2023-12-07T04:21:45.186368Z","shell.execute_reply":"2023-12-07T04:22:56.951593Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/208 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945d1e2dd29c4193bb4b29416a1a7af5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:247: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T04:22:56.954567Z","iopub.execute_input":"2023-12-07T04:22:56.954864Z","iopub.status.idle":"2023-12-07T05:38:12.427657Z","shell.execute_reply.started":"2023-12-07T04:22:56.954837Z","shell.execute_reply":"2023-12-07T05:38:12.426677Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231207_042500-uhm8h787</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/neupane9sujal/huggingface/runs/uhm8h787' target=\"_blank\">finetuning-llama2-chat-7b</a></strong> to <a href='https://wandb.ai/neupane9sujal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/neupane9sujal/huggingface' target=\"_blank\">https://wandb.ai/neupane9sujal/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/neupane9sujal/huggingface/runs/uhm8h787' target=\"_blank\">https://wandb.ai/neupane9sujal/huggingface/runs/uhm8h787</a>"},"metadata":{}},{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 1:12:34, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>2.598800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>2.412000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.375000</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>2.353100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>2.396500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>2.412900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>2.358500</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>2.321100</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>2.311400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.338100</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>2.280700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.196300</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>2.302300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.227700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.210400</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>2.208500</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>2.243100</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>2.274600</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>2.223700</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.230500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2000, training_loss=2.3137620620727537, metrics={'train_runtime': 4515.1375, 'train_samples_per_second': 0.443, 'train_steps_per_second': 0.443, 'total_flos': 492945782784000.0, 'train_loss': 2.3137620620727537, 'epoch': 0.01})"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login, HfApi\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:38:19.403537Z","iopub.execute_input":"2023-12-07T05:38:19.404344Z","iopub.status.idle":"2023-12-07T05:38:19.432537Z","shell.execute_reply.started":"2023-12-07T05:38:19.404306Z","shell.execute_reply":"2023-12-07T05:38:19.431521Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62ba76cd40714a2ba09fd2783a51bd1b"}},"metadata":{}}]},{"cell_type":"code","source":"api = HfApi()\n\napi.upload_folder(\n    folder_path='/working/checkpoint-2000',\n    path_in_repo=\".\",\n    repo_id=\"Neupane9Sujal/llama-gptq-medical-finetuned-chatbot\",\n    repo_type='model',\n    create_pr=1\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:39:04.232726Z","iopub.execute_input":"2023-12-07T05:39:04.233614Z","iopub.status.idle":"2023-12-07T05:39:35.823332Z","shell.execute_reply.started":"2023-12-07T05:39:04.233579Z","shell.execute_reply":"2023-12-07T05:39:35.822073Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"rng_state.pth:   0%|          | 0.00/14.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfcfbb73df64598aad7e4fbc1b7bf99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9131ae17ff04788878ea6c14dfd361a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ceb5b74ff7a4f67b6a1325b6d041c17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/320M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b33a7f462caf481ba7c062a31a60c61e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 6 LFS files:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99e97a4b646645fc94e3d5d787529873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/160M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261af464cde449659b98fd05a90e8728"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b4b0e5ef54c4690b8b0a458a714b83a"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/Neupane9Sujal/llama-gptq-medical-finetuned-chatbot/tree/refs%2Fpr%2F1/.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(\n    model_ckpt,\n    revision='main',\n   quantization_config=quantization_config,\n    device_map='auto')","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:40:09.327091Z","iopub.execute_input":"2023-12-07T05:40:09.327730Z","iopub.status.idle":"2023-12-07T05:40:13.628127Z","shell.execute_reply.started":"2023-12-07T05:40:09.327697Z","shell.execute_reply":"2023-12-07T05:40:13.627144Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"You passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import PeftModel\n\nft_model = PeftModel.from_pretrained(base_model, \"/working/checkpoint-2000\")","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:40:22.278700Z","iopub.execute_input":"2023-12-07T05:40:22.279090Z","iopub.status.idle":"2023-12-07T05:40:23.480146Z","shell.execute_reply.started":"2023-12-07T05:40:22.279059Z","shell.execute_reply":"2023-12-07T05:40:23.479082Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_ckpt, add_bos_token=True, trust_remote_code=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:40:29.730627Z","iopub.execute_input":"2023-12-07T05:40:29.730980Z","iopub.status.idle":"2023-12-07T05:40:29.901494Z","shell.execute_reply.started":"2023-12-07T05:40:29.730951Z","shell.execute_reply":"2023-12-07T05:40:29.900452Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"eval_prompt = \"[INST] Discuss the role of exercise in maintaining a healthy weight and its impact on overall well-being. [/INST]\"\nmodel_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n\nft_model.eval()\nwith torch.no_grad():\n    print(tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-12-07T05:40:33.340286Z","iopub.execute_input":"2023-12-07T05:40:33.341137Z","iopub.status.idle":"2023-12-07T05:41:49.537463Z","shell.execute_reply.started":"2023-12-07T05:40:33.341107Z","shell.execute_reply":"2023-12-07T05:41:49.534601Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[INST] Discuss the role of exercise in maintaining a healthy weight and its impact on overall well-being. [/INST] Exercise is an important component of any weight loss program, as it helps to burn calories and build muscle mass. Regular physical activity can also help to improve cardiovascular function, reduce stress levels, boost mood, and enhance sleep quality. In addition, regular exercise has been shown to have numerous other benefits for overall health and wellness, including reducing blood pressure, improving insulin sensitivity, and lowering cholesterol levels. While di\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Output\n\n","metadata":{}},{"cell_type":"markdown","source":"[INST] Discuss the role of exercise in maintaining a healthy weight and its impact on overall well-being. [/INST] Exercise is an important component of any weight loss program, as it helps to burn calories and build muscle mass. Regular physical activity can also help to improve cardiovascular function, reduce stress levels, boost mood, and enhance sleep quality. In addition, regular exercise has been shown to have numerous other benefits for overall health and wellness, including reducing blood pressure, improving insulin sensitivity, and lowering cholesterol levels. While di","metadata":{}}]}